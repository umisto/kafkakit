// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: inbox.sql

package pgdb

import (
	"context"
	"database/sql"
	"encoding/json"
	"time"

	"github.com/google/uuid"
	"github.com/lib/pq"
)

const createInboxEvent = `-- name: CreateInboxEvent :one
INSERT INTO inbox_events (
    id, topic, key, type, version, producer, payload,
    kafka_partition, kafka_offset
) VALUES (
    $1, $2, $3, $4, $5, $6, $7,
    $8, $9
)
ON CONFLICT (topic, kafka_partition, kafka_offset)
WHERE kafka_partition IS NOT NULL AND kafka_offset IS NOT NULL
DO NOTHING
RETURNING id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
`

type CreateInboxEventParams struct {
	ID             uuid.UUID
	Topic          string
	Key            string
	Type           string
	Version        int32
	Producer       string
	Payload        json.RawMessage
	KafkaPartition sql.NullInt32
	KafkaOffset    sql.NullInt64
}

func (q *Queries) CreateInboxEvent(ctx context.Context, arg CreateInboxEventParams) (InboxEvent, error) {
	row := q.db.QueryRowContext(ctx, createInboxEvent,
		arg.ID,
		arg.Topic,
		arg.Key,
		arg.Type,
		arg.Version,
		arg.Producer,
		arg.Payload,
		arg.KafkaPartition,
		arg.KafkaOffset,
	)
	var i InboxEvent
	err := row.Scan(
		&i.ID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Status,
		&i.Attempts,
		&i.LastAttemptAt,
		&i.CreatedAt,
		&i.KafkaPartition,
		&i.KafkaOffset,
		&i.NextRetryAt,
		&i.ProcessedAt,
	)
	return i, err
}

const getInboxEventByID = `-- name: GetInboxEventByID :one
SELECT id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
FROM inbox_events
WHERE id = $1
`

func (q *Queries) GetInboxEventByID(ctx context.Context, id uuid.UUID) (InboxEvent, error) {
	row := q.db.QueryRowContext(ctx, getInboxEventByID, id)
	var i InboxEvent
	err := row.Scan(
		&i.ID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Status,
		&i.Attempts,
		&i.LastAttemptAt,
		&i.CreatedAt,
		&i.KafkaPartition,
		&i.KafkaOffset,
		&i.NextRetryAt,
		&i.ProcessedAt,
	)
	return i, err
}

const getPendingInboxEventsByKey = `-- name: GetPendingInboxEventsByKey :many
SELECT id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
FROM inbox_events
WHERE status = 'pending'
  AND key = $1
  AND next_retry_at <= (now() AT TIME ZONE 'UTC')
ORDER BY seq ASC
LIMIT $2
FOR UPDATE SKIP LOCKED
`

type GetPendingInboxEventsByKeyParams struct {
	Key   string
	Limit int32
}

func (q *Queries) GetPendingInboxEventsByKey(ctx context.Context, arg GetPendingInboxEventsByKeyParams) ([]InboxEvent, error) {
	rows, err := q.db.QueryContext(ctx, getPendingInboxEventsByKey, arg.Key, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []InboxEvent
	for rows.Next() {
		var i InboxEvent
		if err := rows.Scan(
			&i.ID,
			&i.Seq,
			&i.Topic,
			&i.Key,
			&i.Type,
			&i.Version,
			&i.Producer,
			&i.Payload,
			&i.Status,
			&i.Attempts,
			&i.LastAttemptAt,
			&i.CreatedAt,
			&i.KafkaPartition,
			&i.KafkaOffset,
			&i.NextRetryAt,
			&i.ProcessedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const markInboxEventsAsFailed = `-- name: MarkInboxEventsAsFailed :many
UPDATE inbox_events
SET
    status = 'failed',
    attempts = attempts + 1,
    last_attempt_at = (now() AT TIME ZONE 'UTC')
WHERE id = ANY($1::uuid[])
    RETURNING id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
`

func (q *Queries) MarkInboxEventsAsFailed(ctx context.Context, ids []uuid.UUID) ([]InboxEvent, error) {
	rows, err := q.db.QueryContext(ctx, markInboxEventsAsFailed, pq.Array(ids))
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []InboxEvent
	for rows.Next() {
		var i InboxEvent
		if err := rows.Scan(
			&i.ID,
			&i.Seq,
			&i.Topic,
			&i.Key,
			&i.Type,
			&i.Version,
			&i.Producer,
			&i.Payload,
			&i.Status,
			&i.Attempts,
			&i.LastAttemptAt,
			&i.CreatedAt,
			&i.KafkaPartition,
			&i.KafkaOffset,
			&i.NextRetryAt,
			&i.ProcessedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const markInboxEventsAsPending = `-- name: MarkInboxEventsAsPending :many
UPDATE inbox_events
SET
    status = 'pending',
    attempts = attempts + 1,
    last_attempt_at = (now() AT TIME ZONE 'UTC'),
    next_retry_at = $1::timestamptz
WHERE id = ANY($2::uuid[])
    RETURNING id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
`

type MarkInboxEventsAsPendingParams struct {
	NextRetryAt time.Time
	Ids         []uuid.UUID
}

func (q *Queries) MarkInboxEventsAsPending(ctx context.Context, arg MarkInboxEventsAsPendingParams) ([]InboxEvent, error) {
	rows, err := q.db.QueryContext(ctx, markInboxEventsAsPending, arg.NextRetryAt, pq.Array(arg.Ids))
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []InboxEvent
	for rows.Next() {
		var i InboxEvent
		if err := rows.Scan(
			&i.ID,
			&i.Seq,
			&i.Topic,
			&i.Key,
			&i.Type,
			&i.Version,
			&i.Producer,
			&i.Payload,
			&i.Status,
			&i.Attempts,
			&i.LastAttemptAt,
			&i.CreatedAt,
			&i.KafkaPartition,
			&i.KafkaOffset,
			&i.NextRetryAt,
			&i.ProcessedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const markInboxEventsAsProcessed = `-- name: MarkInboxEventsAsProcessed :many
UPDATE inbox_events
SET
    status = 'processed',
    processed_at = (now() AT TIME ZONE 'UTC')
WHERE id = ANY($1::uuid[])
    RETURNING id, seq, topic, key, type, version, producer, payload, status, attempts, last_attempt_at, created_at, kafka_partition, kafka_offset, next_retry_at, processed_at
`

func (q *Queries) MarkInboxEventsAsProcessed(ctx context.Context, ids []uuid.UUID) ([]InboxEvent, error) {
	rows, err := q.db.QueryContext(ctx, markInboxEventsAsProcessed, pq.Array(ids))
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []InboxEvent
	for rows.Next() {
		var i InboxEvent
		if err := rows.Scan(
			&i.ID,
			&i.Seq,
			&i.Topic,
			&i.Key,
			&i.Type,
			&i.Version,
			&i.Producer,
			&i.Payload,
			&i.Status,
			&i.Attempts,
			&i.LastAttemptAt,
			&i.CreatedAt,
			&i.KafkaPartition,
			&i.KafkaOffset,
			&i.NextRetryAt,
			&i.ProcessedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const pickPendingInboxKey = `-- name: PickPendingInboxKey :one
SELECT e.key
FROM inbox_events e
LEFT JOIN inbox_key_state ks ON ks.key = e.key
LEFT JOIN inbox_key_locks kl ON kl.key = e.key
WHERE e.status = 'pending'
    AND e.next_retry_at <= (now() AT TIME ZONE 'UTC')
    AND (ks.blocked_until IS NULL OR ks.blocked_until <= (now() AT TIME ZONE 'UTC'))
    AND (kl.key IS NULL OR kl.stale_at <= (now() AT TIME ZONE 'UTC'))
ORDER BY e.seq ASC
    LIMIT 1
`

func (q *Queries) PickPendingInboxKey(ctx context.Context) (string, error) {
	row := q.db.QueryRowContext(ctx, pickPendingInboxKey)
	var key string
	err := row.Scan(&key)
	return key, err
}
